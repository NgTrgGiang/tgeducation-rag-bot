"""
chatbot.py - RAG Chatbot k·∫øt h·ª£p Retriever + LLM (OpenRouter ho·∫∑c Ollama local)

Flow:
1. Nh·∫≠n c√¢u h·ªèi t·ª´ user
2. Retriever t√¨m top-K chunks li√™n quan t·ª´ ChromaDB
3. X√¢y d·ª±ng prompt v·ªõi context
4. G·ª≠i cho LLM API (OpenAI-compatible) ƒë·ªÉ sinh c√¢u tr·∫£ l·ªùi
5. Tr·∫£ v·ªÅ c√¢u tr·∫£ l·ªùi + sources
"""
from openai import OpenAI
from retriever import Retriever
from config import OPENROUTER_API_KEY, LLM_BASE_URL, LLM_MODEL, SYSTEM_PROMPT, TOP_K


class RAGChatbot:
    """RAG-powered chatbot for TG Education customer support."""

    def __init__(self):
        print("‚è≥ ƒêang kh·ªüi t·∫°o RAG Chatbot...")

        # Init retriever
        self.retriever = Retriever()

        # Detect mode: local (Ollama) or cloud (OpenRouter)
        self.is_local = "localhost" in LLM_BASE_URL or "127.0.0.1" in LLM_BASE_URL

        if self.is_local:
            # Ollama - kh√¥ng c·∫ßn API key
            self.client = OpenAI(
                base_url=LLM_BASE_URL,
                api_key="ollama",  # Ollama kh√¥ng ki·ªÉm tra key
            )
            provider = "Ollama (local)"
        else:
            # OpenRouter - c·∫ßn API key
            if not OPENROUTER_API_KEY or OPENROUTER_API_KEY == "your_openrouter_api_key_here":
                raise ValueError(
                    "‚ùå Ch∆∞a c·∫•u h√¨nh OPENROUTER_API_KEY!\n"
                    "üëâ L·∫•y API key t·∫°i: https://openrouter.ai/keys\n"
                    "üëâ Ho·∫∑c d√πng Ollama local: LLM_BASE_URL=http://localhost:11434/v1"
                )
            self.client = OpenAI(
                base_url=LLM_BASE_URL,
                api_key=OPENROUTER_API_KEY,
            )
            provider = "OpenRouter"

        self.model = LLM_MODEL
        print(f"‚úÖ RAG Chatbot s·∫µn s√†ng! (Model: {self.model} via {provider})")

    def chat(self, user_message: str, chat_history: list = None) -> dict:
        """
        X·ª≠ l√Ω c√¢u h·ªèi t·ª´ user.

        Args:
            user_message: C√¢u h·ªèi c·ªßa kh√°ch h√†ng
            chat_history: L·ªãch s·ª≠ chat (optional)

        Returns:
            dict v·ªõi keys: answer, sources, escalation_needed, handoff_hint
        """
        # 1. Retrieve relevant documents
        results = self.retriever.search(user_message, top_k=TOP_K)

        # 2. Build context from retrieved documents
        context = self.retriever.format_context(results)

        # 3. Check if escalation is needed
        escalation_needed = any(r.get("escalation_required") for r in results)
        handoff_hints = [
            r["human_handoff_hint"]
            for r in results
            if r.get("escalation_required") and r.get("human_handoff_hint")
        ]

        # 4. Build messages for OpenAI-compatible API
        messages = self._build_messages(user_message, context, chat_history)

        # 5. Call OpenRouter
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                max_tokens=1024,
                temperature=0.3,
            )
            answer = response.choices[0].message.content
        except Exception as e:
            answer = f"Xin l·ªói, ƒë√£ c√≥ l·ªói x·∫£y ra khi x·ª≠ l√Ω c√¢u h·ªèi. Vui l√≤ng th·ª≠ l·∫°i sau.\n(L·ªói: {str(e)})"

        # 6. Build sources list
        sources = [
            {"id": r["id"], "title": r["title"], "category": r["category"]}
            for r in results[:3]
        ]

        return {
            "answer": answer,
            "sources": sources,
            "escalation_needed": escalation_needed,
            "handoff_hint": handoff_hints[0] if handoff_hints else "",
        }

    def _build_messages(self, question: str, context: str, chat_history: list = None) -> list:
        """X√¢y d·ª±ng messages array cho OpenAI-compatible API."""
        messages = [{"role": "system", "content": SYSTEM_PROMPT}]

        # Add chat history
        if chat_history:
            for msg in chat_history[-6:]:
                messages.append({
                    "role": msg["role"],
                    "content": msg["content"],
                })

        # Add context + current question
        user_content = f"""CONTEXT (Th√¥ng tin t·ª´ knowledge base):
{context}

C√ÇU H·ªéI C·ª¶A KH√ÅCH H√ÄNG:
{question}"""

        messages.append({"role": "user", "content": user_content})

        return messages


# === CLI test mode ===
if __name__ == "__main__":
    bot = RAGChatbot()

    print("\n" + "=" * 60)
    print("ü§ñ TG Education RAG Chatbot - CLI Mode")
    print(f"   Model: {bot.model} (via OpenRouter)")
    print("   G√µ 'quit' ƒë·ªÉ tho√°t")
    print("=" * 60)

    history = []
    while True:
        question = input("\nüë§ B·∫°n: ").strip()
        if question.lower() in ["quit", "exit", "q"]:
            print("üëã T·∫°m bi·ªát!")
            break
        if not question:
            continue

        result = bot.chat(question, history)

        print(f"\nü§ñ Tr·ª£ l√Ω: {result['answer']}")

        if result["sources"]:
            print(f"\nüìö Ngu·ªìn tham kh·∫£o:")
            for s in result["sources"]:
                print(f"   - [{s['id']}] {s['title']}")

        if result["escalation_needed"]:
            print(f"\n‚ö†Ô∏è L∆∞u √Ω: {result['handoff_hint']}")

        history.append({"role": "user", "content": question})
        history.append({"role": "assistant", "content": result["answer"]})
